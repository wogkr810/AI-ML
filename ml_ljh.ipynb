{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml-ljh",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ujs1rvbOGIX"
      },
      "source": [
        "모듈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8cnmYc2OClP"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from keras.layers import *\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import numpy as np\n",
        "import tensorflow as tf # 1.15.0 버전 사용\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from sklearn.svm import LinearSVC\n",
        "from numpy import array\n",
        "from keras.layers import  LSTM\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YYCb8k8OFYK"
      },
      "source": [
        "데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjWk1SHeORyg",
        "outputId": "c4d199da-9f62-44bd-fe9e-accb8a5b57de"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "#x_train\n",
        "train_data_path = \"/content/gdrive/My Drive/21ML/data/train_data.npy\"\n",
        "train_data = np.load(train_data_path, allow_pickle=True)\n",
        "train_data_path1 = \"/content/gdrive/My Drive/21ML/data/test_data.npy\"  \n",
        "train_data1 = np.load(train_data_path1, allow_pickle=True)\n",
        "x_train=np.append(train_data,train_data1)\n",
        "num_train_data = len(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1zjpGsjTIUV",
        "outputId": "91569cde-62a3-495a-9772-e554cc08d69c"
      },
      "source": [
        "np.abs(x_train[0][-1][0].reshape(361))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTJhRJQcY0Ee"
      },
      "source": [
        "#x_label\n",
        "train_label_path = \"/content/gdrive/My Drive/21ML/data/train_label.npy\"\n",
        "train_label = np.load(train_label_path, allow_pickle=True)\n",
        "train_label_path1 = \"/content/gdrive/My Drive/21ML/data/test_label2.npy\"  \n",
        "train_label1 = np.load(train_label_path1, allow_pickle=True)\n",
        "label_raw=np.append(train_label,train_label1)\n",
        "rating = ['18k', '17k', '16k', '15k', '14k', '13k', '12k', '11k', '10k', \n",
        "          '9k', '8k', '7k', '6k', '5k', '4k', '3k', '2k', '1k',\n",
        "          '1d', '2d', '3d', '4d', '5d', '6d', '7d', '8d', '9d']\n",
        "x_label=np.zeros(num_train_data)\n",
        "for i in range(num_train_data):\n",
        "  train_label_temp = label_raw[i]\n",
        "  train_label_idx = rating.index(train_label_temp)\n",
        "  x_label[i] = train_label_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n6WPOcW9UEH"
      },
      "source": [
        "#예측데이터\n",
        "test_data_path = \"/content/gdrive/My Drive/21ML/data/Test2_data.npy\"\n",
        "test_data = np.load(test_data_path, allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1iPOE9gOj90",
        "outputId": "32e60e72-4f80-42f8-dca5-8a5b5a62c163"
      },
      "source": [
        "#마지막판 저장\n",
        "last_train_data = np.zeros( (num_train_data, 19,19), dtype=int) \n",
        "for i in range(num_train_data):\n",
        "  temp_last_data = train_data[i][-1]\n",
        "  last_train_data[i, 0:, :] = temp_last_data\n",
        "last_train_data = np.reshape(last_train_data,(num_train_data, 19*19))\n",
        "print(last_train_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2682, 361)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAWCMv-LPFUG",
        "outputId": "27b7a511-6868-4bf2-c9e9-296e281ce5d1"
      },
      "source": [
        "#svm\n",
        "clf = LinearSVC(random_state=1)\n",
        "clf.fit(last_train_data, train_label)\n",
        "num_test_data = len(test_data)\n",
        "last_test_data = np.zeros( (num_test_data, 19, 19) )\n",
        "for i in range(num_test_data):\n",
        "  temp_last_data = test_data[i][-1]\n",
        "  last_test_data[i, :, :] = temp_last_data\n",
        "last_test_data = np.reshape(last_test_data, (num_test_data, 19*19))\n",
        "pred_test_label = clf.predict(last_test_data)\n",
        "pred_test_label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKCKjLNTYJLr"
      },
      "source": [
        "#제출용 label 바꾸기\n",
        "pred_test_label = model1.predict(test_data)\n",
        "pred_test_label_txt = list_data = [str(rating[int(a)]).strip('\\n\\r') for a in pred_test_label]\n",
        "print(pred_test_label_txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ9jiBZMyVCa"
      },
      "source": [
        "#svc 반복\n",
        "def my_classification(train_data,train_label,test_data,random_state):\n",
        "  svc=SVC(kernel='linear',probability=True)\n",
        "  svc_model=svc.fit(train_data,train_label)\n",
        "  return svc_model.predict_proba(test_data)\n",
        "repeat=9\n",
        "prob=[]\n",
        "for k in range(repeat):\n",
        "  num_test_data=len(test_data)\n",
        "  my_train_data=np.zeros(((num_train_data,19,19)))\n",
        "  for i in range(num_train_data):\n",
        "    if k==0:\n",
        "      temp_my_data1=train_data[i][np.min((k,len(train_data[i])-1))]\n",
        "    else:\n",
        "      temp_my_data1=train_data[i][np.min((k,len(train_data[i])-1))]-train_data[i][np.min((k-1,len(train_data[i])-1))]\n",
        "    my_train_data[i,:,:]=temp_my_data1\n",
        "    \n",
        "  my_train_data=np.reshape(my_train_data,(num_train_data,19*19))\n",
        "  my_test_data=np.zeros(((num_test_data,19,19)))\n",
        "  for i in range(num_test_data):\n",
        "    if k==0:\n",
        "      temp_my_data1=test_data[i][np.min((k,len(test_data[i])-1))]\n",
        "    else:\n",
        "      temp_my_data1=test_data[i][np.min((k,len(test_data[i])-1))]-test_data[i][np.min((k-1,len(test_data[i])-1))]\n",
        "    my_test_data[i,:,:]=temp_my_data1\n",
        "  \n",
        "  my_test_data=np.reshape(my_test_data,(num_test_data,19*19))\n",
        "  p=my_classification(my_train_data,train_label,my_test_data,k)\n",
        "  if prob==[]:\n",
        "    prob=p\n",
        "  else:\n",
        "    prob+=p+max(1-k*(0.1),0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJUzk6TSzxm3",
        "outputId": "ed395129-be8a-4a2d-da31-555d93f39664"
      },
      "source": [
        "#Ensemble 2\n",
        "from sklearn.svm import LinearSVC\n",
        "def my_classification_only_prediction(train_data, train_label, test_data, random_state):\n",
        "  clf = LinearSVC(random_state=1)\n",
        "  clf.fit(train_data, train_label)  \n",
        "  return clf.predict(test_data)\n",
        "import numpy as np\n",
        "k1 = 5\n",
        "k2 = 10\n",
        "# Get last test data\n",
        "num_test_data = len(test_data)\n",
        "\n",
        "my_train_data = np.zeros(((num_train_data, k2-k1, 19, 19)))\n",
        "\n",
        "for i in range(len(x_train)):\n",
        "\n",
        "  temp_my_data = []\n",
        "  for t in range(k1,k2):    \n",
        "    if temp_my_data==[]:\n",
        "      temp_my_data = x_train[i][ np.min((np.max(t,0), len(x_train[i])-1))]\n",
        "    else:\n",
        "      t_data = x_train[i][ np.min((np.max(t,0), len(x_train[i])-1))]  - x_train[i][ np.min((np.max(t-1,0), len(x_train[i])-1)) ]  \n",
        "      temp_my_data = np.concatenate( (t_data, temp_my_data), axis=0 )\n",
        "  my_train_data[i, :, :, :] = temp_my_data\n",
        "\n",
        "my_train_data = np.reshape(my_train_data, (num_train_data, -1))\n",
        "\n",
        "my_test_data = np.zeros(((num_test_data, k2-k1, 19, 19)))\n",
        "\n",
        "for i in range(num_test_data):\n",
        "\n",
        "  temp_my_data = []\n",
        "  for t in range(k1,k2):\n",
        "    if temp_my_data==[]:  \n",
        "      temp_my_data = test_data[i][ np.min((np.max(t,0), len(test_data[i])-1))]\n",
        "      #temp_my_data = temp_my_data/np.sum(np.abs(temp_my_data))\n",
        "    else:\n",
        "      t_data = test_data[i][ np.min((np.max(t,0), len(test_data[i])-1))]  - test_data[i][ np.min((np.max(t-1,0), len(test_data[i])-1)) ]  \n",
        "      temp_my_data = np.concatenate( (t_data, temp_my_data), axis=0 )\n",
        "\n",
        "  my_test_data[i, :, :] = temp_my_data\n",
        "\n",
        "my_test_data = np.reshape(my_test_data, (num_test_data, -1))\n",
        "predicted_label = my_classification_only_prediction(my_train_data, x_label, my_test_data, 10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBecQ6-X1bua"
      },
      "source": [
        "#제출용 pip install 및 json \n",
        "import json\n",
        "from base64 import b64encode\n",
        "from Cryptodome.Cipher import AES\n",
        "from Cryptodome.Util.Padding import pad\n",
        "\n",
        "def read_txt(fileName):\n",
        "    with open(fileName, 'rt') as f:\n",
        "        list_data = [a.strip('\\n\\r') for a in f.readlines()]\n",
        "    return list_data\n",
        "\n",
        "def write_json(fileName, data):\n",
        "    with open(fileName, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "def load_key(key_path):\n",
        "    with open(key_path, \"rb\") as f:\n",
        "        key = f.read()\n",
        "    return key\n",
        "\n",
        "def encrypt_data(key_path, ans_list, encrypt_store_path='ans.json'):\n",
        "    key = load_key(key_path)\n",
        "    data = \" \".join([str(i) for i in ans_list])\n",
        "    encode_data = data.encode()\n",
        "    cipher = AES.new(key, AES.MODE_CBC)\n",
        "    ct_bytes = cipher.encrypt(pad(encode_data, AES.block_size))\n",
        "    iv = b64encode(cipher.iv).decode('utf-8')\n",
        "    ct = b64encode(ct_bytes).decode('utf-8')\n",
        "    write_json(encrypt_store_path, {'iv':iv, 'ciphertext':ct})\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    # 1.이메일을 통해서 전달 받은 키 파일의 경로 입력\n",
        "    key_path =\"/content/gdrive/My Drive/21ML/제출관련/team13 (1).pem\"\n",
        "    # 2. 예측한 결과를 텍스트 파일로 저장했을 경우 리스트로 다시 불러오기\n",
        "    # 본인이 원하는 방식으로 리스트 형태로 예측 값을 불러오기만 하면 됨(순서를 지킬것)\n",
        "    #raw_ans_path = \"ans.txt\"\n",
        "    #ans = read_txt(raw_ans_path)\n",
        "    ans = pred_test_label_txt\n",
        "    # 3. 암호화된 파일을 저장할 위치\n",
        "    encrypt_ans_path = \"/content/gdrive/My Drive/21ML/ans13.json\"\n",
        "    # 4. 암호화!(pycrytodome 설치)\n",
        "    encrypt_data(key_path, ans, encrypt_ans_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}